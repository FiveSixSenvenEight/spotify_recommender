{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262292\n",
      "22622\n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "d = {'pl':pd.read_csv(data_path+'pl_tracks.csv'),\\\n",
    "     't':pd.read_csv(data_path+'tracks.csv')}\n",
    "\n",
    "# Calculate popularity: number of occurances\n",
    "pop = d['pl'].groupby('track_uri').count().reset_index()\n",
    "pop.columns = ['track_uri', 'popularity']\n",
    "df = pd.merge(d['t'], pop, on = 'track_uri', how = 'left')\n",
    "\n",
    "# Define the list of track_uri ordered by popularity\n",
    "pop_sorted_tracks = df.sort_values('popularity', ascending = False)['track_uri'].values.tolist()\n",
    "print(len(pop_sorted_tracks))\n",
    "pop_sorted_tracks = pop_sorted_tracks[:(len(pop_sorted_tracks)//100)]\n",
    "print(len(pop_sorted_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_test_data.pkl\", \"rb\") as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_similarity(pl1, pl2):\n",
    "    ''' We define the similarity between playlists to be:\n",
    "        # overlap songs / min(len(pl1), len(pl2))'''\n",
    "    overlap = sum([a in pl2 for a in pl1])\n",
    "    return overlap / min(len(pl1), len(pl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_map(X, similarity_fn, prefix, save = True):\n",
    "    ''' Calcualte the pair-wise similarity between all keys in X, using similarity_fn. '''\n",
    "    all_keys = list(X.keys())\n",
    "    similarity_dict = {(a,b):np.inf for a in all_keys for b in all_keys}\n",
    "    for i in range(len(all_keys)):\n",
    "        if i % (len(all_keys)//10) == 0: print(i)\n",
    "        for j in range(i, len(all_keys)):\n",
    "            this_pl = all_keys[i]\n",
    "            other_pl = all_keys[j]\n",
    "            dist = similarity_fn(X[this_pl], X[other_pl])\n",
    "            similarity_dict[(this_pl, other_pl)] = dist\n",
    "            similarity_dict[(other_pl, this_pl)] = dist\n",
    "    if save:\n",
    "        with open(data_path + prefix + \"_similarity_map.pkl\", \"wb\") as f:\n",
    "            pickle.dump(similarity_dict, f)\n",
    "\n",
    "def load_similarity_map(prefix = 'X_train'):\n",
    "    ''' Loads a pre-calculated similarity map '''\n",
    "    with open(data_path + prefix + \"_similarity_map.pkl\", \"rb\") as f:\n",
    "        similarity_dict = pickle.load(f)\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train KNN Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity map for X_train\n",
    "# calc_similarity_map(X_train, overlap_similarity, prefix ='X_train')\n",
    "similarity_dict = load_similarity_map(prefix ='X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_dict(X, similarity_dict, n_neighbors = 100):\n",
    "    ''' Use the input X to find the n_neighbors neighbors for each playlist using \n",
    "        precalculated similaritys from similarity_dict. '''\n",
    "    all_keys = X.keys()\n",
    "    neighbor_dict = {k:[] for k in all_keys}\n",
    "    neighbor_sim_dict = {k:[] for k in all_keys}\n",
    "    for i in range(len(all_keys)):\n",
    "        this_pl = list(all_keys)[i]\n",
    "        # similarity between the current pl and other pls\n",
    "        dist_dict_temp = {x:-np.inf for x in all_keys}\n",
    "        for other_pl in all_keys:\n",
    "            if this_pl != other_pl:\n",
    "                dist_dict_temp[other_pl] = similarity_dict[(this_pl, other_pl)]\n",
    "        dist_dict_temp = sorted(dist_dict_temp.items(), key = lambda x:x[1], reverse = True)[:n_neighbors]\n",
    "        neighbor_dict[this_pl] = [a[0] for a in dist_dict_temp]\n",
    "        neighbor_sim_dict[this_pl] = [a[1] for a in dist_dict_temp]\n",
    "    return neighbor_dict, neighbor_sim_dict\n",
    "\n",
    "def load_neighbor_map(prefix = 'X_train'):\n",
    "    ''' Loads a pre-calculated neighbor map along with similarity map. '''\n",
    "    with open(data_path + prefix + \"_neighbor_sim_map.pkl\", \"rb\") as f:\n",
    "        neighbor_dict, neighbor_sim_dict = pickle.load(f)\n",
    "    return neighbor_dict, neighbor_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['835_542', '350_59', '465_645', '546_161', '730_669', '793_316', '827_584', '832_718', '843_654', '890_122', '62_367', '509_938', '33_907', '35_9', '354_189', '375_843', '38_958', '389_392', '401_227', '406_65', '410_772', '42_850', '441_485', '449_295', '45_544', '5_476', '503_429', '505_685', '52_639', '537_312', '540_87', '577_192', '588_255', '591_112', '592_359', '594_976', '598_479', '603_163', '613_638', '624_551', '631_834', '638_907', '640_189', '651_785', '652_334', '654_949', '692_959', '729_320', '779_206', '779_279', '785_448', '795_836', '797_820', '801_341', '805_986', '808_668', '813_75', '815_36', '830_801', '843_948', '845_905', '859_386', '863_360', '866_727', '891_406', '895_755', '897_629', '90_445', '903_928', '928_957', '937_444', '939_638', '948_692', '959_485', '969_284', '396_382', '42_472', '662_934', '817_116', '828_566', '394_459', '80_258', '802_321', '85_722', '37_39', '387_428', '411_644', '512_39', '60_846', '782_393', '836_622', '982_186', '994_218', '323_756', '325_664', '325_834', '326_12', '326_559', '330_173', '331_640']\n",
      "[0.3076923076923077, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.18181818181818182, 0.16666666666666666, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.1, 0.1, 0.1, 0.1, 0.1, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.09090909090909091, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693]\n"
     ]
    }
   ],
   "source": [
    "# # Calculate neighbor_dict, neighbor_sim_dict for the first time \n",
    "# neighbor_dict, neighbor_sim_dict = get_neighbor_dict(X_train, similarity_dict)\n",
    "# print(neighbor_dict[list(neighbor_dict.keys())[0]])\n",
    "# print(neighbor_sim_dict[list(neighbor_dict.keys())[0]])\n",
    "\n",
    "# with open(data_path + \"X_train_neighbor_sim_map.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((neighbor_dict, neighbor_sim_dict), f)\n",
    "    \n",
    "# Load saved neighbor_dict, neighbor_sim_dict\n",
    "neighbor_dict, neighbor_sim_dict = load_neighbor_map(prefix = 'X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_ranking_algo(X, similarity_dict, mode = 'train', n_neighbors = 100, n_preds = 10):    \n",
    "    ''' The main algorithm that predicts n_preds songs for each of the input playlist. '''\n",
    "    # Update the neighbor_dict and neighbor_sim_dict based on mode\n",
    "    neighbor_dict, neighbor_sim_dict = load_neighbor_map(prefix = 'X_'+mode)\n",
    "    pl_orig_song_lookup = X.copy()\n",
    "    if mode != 'train':\n",
    "        for k,v in X_test.items():\n",
    "            pl_orig_song_lookup[k] = v\n",
    "    \n",
    "    predictions = []\n",
    "    num_runs = len(pl_orig_song_lookup.keys())\n",
    "    # Loop over all of the \n",
    "    for pl_id, contained in pl_orig_song_lookup.items():\n",
    "        if len(predictions) % (num_runs//100) == 0: print(len(predictions))\n",
    "        non_contain = [h for h in pop_sorted_tracks if h not in contained]\n",
    "        # For all the non_contain songs and all neighbors of pl_id, calculates the score\n",
    "        song_scores = []\n",
    "        for a_song in non_contain:\n",
    "            score = 0\n",
    "            neighbors = neighbor_dict[pl_id]\n",
    "            for neighbor_ind, neighbor in enumerate(neighbors):\n",
    "                neighbor_songs = pl_orig_song_lookup[neighbor]\n",
    "                if a_song in neighbor_songs:\n",
    "                    score += neighbor_sim_dict[pl_id][neighbor_ind]\n",
    "            song_scores.append(score)\n",
    "        # Predict the songs with the highest score\n",
    "        best_songs = np.array(song_scores).argsort()[-n_preds:][::-1]\n",
    "        pred = [non_contain[i] for i in best_songs]\n",
    "        predictions.append(pred)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_score(tracks, pred_tracks, test_size = 10):\n",
    "    ''' Computes the overlap score for tracks and pred_tracks. \n",
    "        returns #overlap'''\n",
    "    assert len(tracks) == len(pred_tracks)\n",
    "    return sum([a in tracks for a in pred_tracks])\n",
    "\n",
    "def avg_overlap(true_dict, pred):\n",
    "    ''' Returns the accuracy score given true_label and pred'''\n",
    "    assert len(true_dict) == len(pred)\n",
    "    avg_overlap = np.mean([overlap_score(a, b) for a,b in zip(true_dict.values(), pred)])    \n",
    "    return avg_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "74\n",
      "148\n",
      "222\n",
      "296\n",
      "370\n",
      "444\n",
      "518\n",
      "592\n",
      "666\n",
      "740\n",
      "814\n",
      "888\n",
      "962\n",
      "1036\n",
      "1110\n",
      "1184\n",
      "1258\n",
      "1332\n",
      "1406\n",
      "1480\n",
      "1554\n",
      "1628\n",
      "1702\n",
      "1776\n",
      "1850\n",
      "1924\n",
      "1998\n",
      "2072\n",
      "2146\n",
      "2220\n",
      "2294\n",
      "2368\n",
      "2442\n",
      "2516\n",
      "2590\n",
      "2664\n",
      "2738\n",
      "2812\n",
      "2886\n",
      "2960\n",
      "3034\n",
      "3108\n",
      "3182\n",
      "3256\n",
      "3330\n",
      "3404\n",
      "3478\n",
      "3552\n",
      "3626\n",
      "3700\n",
      "3774\n",
      "3848\n",
      "3922\n",
      "3996\n",
      "4070\n",
      "4144\n",
      "4218\n",
      "4292\n",
      "4366\n",
      "4440\n",
      "4514\n",
      "4588\n",
      "4662\n",
      "4736\n",
      "4810\n",
      "4884\n",
      "4958\n",
      "5032\n",
      "5106\n",
      "5180\n",
      "5254\n",
      "5328\n",
      "5402\n",
      "5476\n",
      "5550\n",
      "5624\n",
      "5698\n",
      "5772\n",
      "5846\n",
      "5920\n",
      "5994\n",
      "6068\n",
      "6142\n",
      "6216\n",
      "6290\n",
      "6364\n",
      "6438\n",
      "6512\n",
      "6586\n",
      "6660\n",
      "6734\n",
      "6808\n",
      "6882\n",
      "6956\n",
      "7030\n",
      "7104\n",
      "7178\n",
      "7252\n",
      "7326\n",
      "7400\n",
      "Average overlap score is: 0.7709086043088452\n"
     ]
    }
   ],
   "source": [
    "predictions = knn_ranking_algo(X_train, similarity_dict, n_neighbors = 100, n_preds = 10)\n",
    "print(\"Average overlap score is:\", avg_overlap(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_data_predictions_knn_ranking.pkl\", \"wb\") as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
