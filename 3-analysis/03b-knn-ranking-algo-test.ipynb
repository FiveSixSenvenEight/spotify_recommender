{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262292\n",
      "22622\n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "d = {'pl':pd.read_csv(data_path+'pl_tracks.csv'),\\\n",
    "     't':pd.read_csv(data_path+'tracks.csv')}\n",
    "\n",
    "# Calculate popularity: number of occurances\n",
    "pop = d['pl'].groupby('track_uri').count().reset_index()\n",
    "pop.columns = ['track_uri', 'popularity']\n",
    "df = pd.merge(d['t'], pop, on = 'track_uri', how = 'left')\n",
    "\n",
    "# Define the list of track_uri ordered by popularity\n",
    "pop_sorted_tracks = df.sort_values('popularity', ascending = False)['track_uri'].values.tolist()\n",
    "print(len(pop_sorted_tracks))\n",
    "pop_sorted_tracks = pop_sorted_tracks[:(len(pop_sorted_tracks)//100)]\n",
    "print(len(pop_sorted_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d, df, pop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"train_test_data.pkl\", \"rb\") as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_similarity(pl1, pl2):\n",
    "    ''' We define the similarity between playlists to be:\n",
    "        # overlap songs / min(len(pl1), len(pl2))'''\n",
    "    overlap = sum([a in pl2 for a in pl1])\n",
    "    return overlap / min(len(pl1), len(pl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n",
      "9998\n"
     ]
    }
   ],
   "source": [
    "# Define X_all and y_all\n",
    "X_all = X_train.copy()\n",
    "for k,v in X_test.items(): X_all[k] = v\n",
    "y_all = y_train.copy()\n",
    "for k,v in y_test.items(): y_all[k] = v\n",
    "print(len(X_all))\n",
    "print(len(y_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, y_train, X_test, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train KNN Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_dict(X, n_neighbors = 100):\n",
    "    ''' Use the input X to find the n_neighbors neighbors for each playlist using \n",
    "        overlap_similarity function. '''\n",
    "    all_keys = X.keys()\n",
    "    neighbor_dict = {k:[] for k in all_keys}\n",
    "    neighbor_sim_dict = {k:[] for k in all_keys}\n",
    "    n_loop = len(all_keys)\n",
    "    for i in range(n_loop):\n",
    "        if i % (n_loop//10) == 0: print(i)\n",
    "        this_pl = list(all_keys)[i]\n",
    "        # similarity between the current pl and other pls\n",
    "        dist_dict_temp = {x:-np.inf for x in all_keys}\n",
    "        for other_pl in all_keys:\n",
    "            if this_pl != other_pl:\n",
    "                dist_dict_temp[other_pl] = overlap_similarity(X[this_pl], X[other_pl]) #similarity_dict[(this_pl, other_pl)]\n",
    "        dist_dict_temp = sorted(dist_dict_temp.items(), key = lambda x:x[1], reverse = True)[:n_neighbors]\n",
    "        neighbor_dict[this_pl] = [a[0] for a in dist_dict_temp]\n",
    "        neighbor_sim_dict[this_pl] = [a[1] for a in dist_dict_temp]\n",
    "    return neighbor_dict, neighbor_sim_dict\n",
    "\n",
    "def load_neighbor_map(prefix = 'X_all'):\n",
    "    ''' Loads a pre-calculated neighbor map along with similarity map. '''\n",
    "    with open(data_path + prefix + \"_neighbor_sim_map.pkl\", \"rb\") as f:\n",
    "        neighbor_dict, neighbor_sim_dict = pickle.load(f)\n",
    "    return neighbor_dict, neighbor_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "999\n",
      "1998\n",
      "2997\n",
      "3996\n",
      "4995\n",
      "5994\n",
      "6993\n",
      "7992\n",
      "8991\n",
      "9990\n",
      "['835_542', '350_59', '465_645', '546_161', '730_669', '793_316', '827_584', '832_718', '843_654', '890_122', '115_982', '134_158', '62_367', '509_938', '33_907', '35_9', '354_189', '375_843', '38_958', '389_392', '401_227', '406_65', '410_772', '42_850', '441_485', '449_295', '45_544', '5_476', '503_429', '505_685', '52_639', '537_312', '540_87', '577_192', '588_255', '591_112', '592_359', '594_976', '598_479', '603_163', '613_638', '624_551', '631_834', '638_907', '640_189', '651_785', '652_334', '654_949', '692_959', '729_320', '779_206', '779_279', '785_448', '795_836', '797_820', '801_341', '805_986', '808_668', '813_75', '815_36', '830_801', '843_948', '845_905', '859_386', '863_360', '866_727', '891_406', '895_755', '897_629', '90_445', '903_928', '928_957', '937_444', '939_638', '948_692', '959_485', '969_284', '106_870', '112_333', '125_42', '125_380', '163_122', '173_633', '177_523', '184_198', '193_815', '2_603', '212_165', '259_571', '286_611', '293_954', '297_948', '306_449', '31_666', '310_901', '396_382', '42_472', '662_934', '817_116', '828_566']\n",
      "[0.3076923076923077, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.23076923076923078, 0.18181818181818182, 0.16666666666666666, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.15384615384615385, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# # Calculate neighbor_dict, neighbor_sim_dict for the first time \n",
    "neighbor_dict, neighbor_sim_dict = get_neighbor_dict(X_all)\n",
    "print(neighbor_dict[list(neighbor_dict.keys())[0]])\n",
    "print(neighbor_sim_dict[list(neighbor_dict.keys())[0]])\n",
    "\n",
    "with open(data_path + \"X_all_neighbor_sim_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump((neighbor_dict, neighbor_sim_dict), f)\n",
    "    \n",
    "# Load saved neighbor_dict, neighbor_sim_dict\n",
    "neighbor_dict, neighbor_sim_dict = load_neighbor_map(prefix = 'X_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_ranking_algo(X, n_neighbors = 100, n_preds = 10):    \n",
    "    ''' The main algorithm that predicts n_preds songs for each of the input playlist. '''\n",
    "    # Update the neighbor_dict and neighbor_sim_dict based on mode\n",
    "    neighbor_dict, neighbor_sim_dict = load_neighbor_map(prefix = 'X_all')\n",
    "    pl_orig_song_lookup = X.copy()\n",
    "    \n",
    "    predictions = []\n",
    "    num_runs = len(pl_orig_song_lookup.keys())\n",
    "    # Loop over all of the \n",
    "    for pl_id, contained in pl_orig_song_lookup.items():\n",
    "        if len(predictions) % (num_runs//50) == 0: print(len(predictions))\n",
    "        non_contain = [h for h in pop_sorted_tracks if h not in contained]\n",
    "        # For all the non_contain songs and all neighbors of pl_id, calculates the score\n",
    "        song_scores = []\n",
    "        for a_song in non_contain:\n",
    "            score = 0\n",
    "            neighbors = neighbor_dict[pl_id]\n",
    "            for neighbor_ind, neighbor in enumerate(neighbors):\n",
    "                neighbor_songs = pl_orig_song_lookup[neighbor]\n",
    "                if a_song in neighbor_songs:\n",
    "                    score += neighbor_sim_dict[pl_id][neighbor_ind]\n",
    "            song_scores.append(score)\n",
    "        # Predict the songs with the highest score\n",
    "        best_songs = np.array(song_scores).argsort()[-n_preds:][::-1]\n",
    "        pred = [non_contain[i] for i in best_songs]\n",
    "        predictions.append(pred)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_score(tracks, pred_tracks, test_size = 10):\n",
    "    ''' Computes the overlap score for tracks and pred_tracks. \n",
    "        returns #overlap'''\n",
    "    assert len(tracks) == len(pred_tracks) == test_size\n",
    "    return sum([a in tracks for a in pred_tracks])\n",
    "\n",
    "def avg_overlap(true_dict, pred):\n",
    "    ''' Returns the accuracy score given true_label and pred'''\n",
    "    assert len(true_dict) == len(pred)\n",
    "    avg_overlap = np.mean([overlap_score(a, b) for a,b in zip(true_dict.values(), pred)])    \n",
    "    return avg_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overlap score is: 0.7987597519503901\n"
     ]
    }
   ],
   "source": [
    "# predictions = knn_ranking_algo(X_all, n_neighbors = 100, n_preds = 10)\n",
    "print(\"Average overlap score is:\", avg_overlap(y_all, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"all_data_predictions_knn_ranking.pkl\", \"wb\") as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
